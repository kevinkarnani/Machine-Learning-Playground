{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('spambase.data', header=None, engine='python')\n",
    "df_x = df_x.sample(frac=1, random_state=0)\n",
    "df_y = pd.DataFrame(data=df_x[df_x.columns[-1]])\n",
    "spam_x, nspam_x = [x for _, x in df_x.groupby(df_x[df_x.columns[-1]] == 0)]\n",
    "spam_y = pd.DataFrame(data=spam_x[spam_x.columns[-1]])\n",
    "nspam_y = pd.DataFrame(data=nspam_x[nspam_x.columns[-1]])\n",
    "df_x.drop(df_x.columns[[-1,]], axis=1, inplace=True)\n",
    "spam_x.drop(spam_x.columns[[-1,]], axis=1, inplace=True)\n",
    "nspam_x.drop(nspam_x.columns[[-1,]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train, df_x_test, df_y_train, df_y_test = tts(df_x, df_y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_x_train.mean(axis=0)\n",
    "std = df_x_train.std(axis=0)\n",
    "df_x_s_train = df_x_train.subtract(mean).divide(std)\n",
    "df_x_s_test = df_x_test.subtract(mean).divide(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_entropy = 0\n",
    "labels = df_y[df_y.columns[0]]\n",
    "target_values = labels.unique()\n",
    "counts = labels.value_counts()\n",
    "for value in target_values:\n",
    "    total_entropy -= (counts[value]/len(labels) * np.log2(counts[value]/len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(data):\n",
    "    data = (data > data.mean(axis=0)).astype(int)\n",
    "    return data\n",
    "\n",
    "def attribute_entropy(x, y, index):\n",
    "    target_value = y[y.columns[0]].unique()\n",
    "    features = x[index].unique()\n",
    "    \n",
    "    attribute_entropy = 0\n",
    "    for feature in features:\n",
    "        feature_entropy = 0\n",
    "        available_features = len(x[index][x[index]==feature][y[y.columns[0]]==target_value[0]])\n",
    "        total_features = len(x[index][x[index]==feature])\n",
    "        feature_prob = (available_features/(total_features + np.finfo(float).eps) + np.finfo(float).eps)\n",
    "        #print(feature_prob)\n",
    "        feature_entropy -= feature_prob * np.log2(feature_prob)\n",
    "        attribute_entropy -= total_features/len(x) * feature_entropy\n",
    "        \n",
    "    return(np.abs(attribute_entropy))\n",
    "\n",
    "df_x_b_train = binarize(df_x_s_train)\n",
    "df_x_b_test = binarize(df_x_s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, val=None):\n",
    "        self.val = val\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "    def setRight(self, right):\n",
    "        self.right = right\n",
    "    def setLeft(self, left):\n",
    "        self.left = left\n",
    "    def setVal(self, val):\n",
    "        self.val = val\n",
    "    def getRight(self):\n",
    "        return self.right\n",
    "    def getLeft(self):\n",
    "        return self.left\n",
    "    def getVal(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 862 68 90\n",
      "0.8959842001316656 0.8800705467372134 0.8471986417657046 0.8633217993079585\n"
     ]
    }
   ],
   "source": [
    "class DT:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "    \n",
    "    def ID3(self, data, attributes, default):\n",
    "        data_x = data[:,:-1]\n",
    "        data_y = data[:,-1]\n",
    "        if len(data_x) == 0:\n",
    "            return Node(default)\n",
    "        elif np.all(data_y) == 1:\n",
    "            return Node(data_y[0])\n",
    "        elif len(attributes) == 1:\n",
    "            return Node(stats.mode(data_y).mode[0])\n",
    "        best = self.attribute_entropy(data, attributes)\n",
    "        root = Node(attributes[best])\n",
    "        new_attr = np.delete(attributes, best)\n",
    "        new_data = np.delete(data, best, 1)\n",
    "        spam = new_data[(data[:,best] == 1)]\n",
    "        nspam = new_data[(data[:,best] == 0)]\n",
    "        right = self.ID3(spam, new_attr, stats.mode(data_y).mode[0])\n",
    "        root.setRight(right)\n",
    "        left = self.ID3(nspam, new_attr, stats.mode(data_y).mode[0])\n",
    "        root.setLeft(left)\n",
    "        return root\n",
    "            \n",
    "    def attribute_entropy(self, x, attributes):\n",
    "        entropies = []\n",
    "        for i in range(len(attributes) - 1):\n",
    "            z_x = x[(x[:,i] == 0)]\n",
    "            z_x_rows = z_x.shape[0]\n",
    "            o_x = x[(x[:,i] == 1)]\n",
    "            o_x_rows = o_x.shape[0]\n",
    "            z_y = z_x[(z_x[:,-1] == 0)]\n",
    "            z_y_rows = z_y.shape[0]\n",
    "            o_y = z_x[(z_x[:,-1] == 1)]\n",
    "            o_y_rows = o_y.shape[1]\n",
    "            o_x_y = o_x[(o_x[:,-1] == 0)]\n",
    "            o_x_y_rows = o_x_y.shape[0]\n",
    "            o_y_y = o_x[(o_x[:,-1] == 1)]\n",
    "            o_y_y_rows = o_y_y.shape[1]\n",
    "            total_z_x = z_x_rows / len(x)\n",
    "            total_o_x = o_x_rows / len(x)\n",
    "            ent1 = self.ent_helper(z_y_rows, o_y_rows, total_z_x)\n",
    "            ent2 = self.ent_helper(o_x_y_rows, o_y_y_rows, total_o_x)\n",
    "            ent = ent1 * total_z_x + ent2 * total_o_x\n",
    "            entropies.append(ent)\n",
    "            \n",
    "        return entropies.index(np.min(entropies))\n",
    "            \n",
    "    def predict(self, root, test_x, test_y):\n",
    "        p = []\n",
    "        for i in range(test_x.shape[0]):\n",
    "            current = root\n",
    "            while not False:\n",
    "                feature = current.getVal()\n",
    "                if test_x.values[i][feature] == 0:\n",
    "                    current = current.getLeft()\n",
    "                else:\n",
    "                    current = current.getRight()\n",
    "                if current.getLeft() is None and current.getRight() is None:\n",
    "                    p.append(current.getVal())\n",
    "                    break;\n",
    "        tp, tn, fp, fn = 0,0,0,0\n",
    "        for i in range(len(p)):\n",
    "            if p[i] == test_y.values[i]:\n",
    "                if p[i] == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if p[i] == 1:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "        accuracy = (tp + tn)/test_y.shape[0]\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "        print(tp, tn, fp, fn)\n",
    "        print(accuracy, precision, recall, f1)\n",
    "                \n",
    "            \n",
    "    def ent_helper(self, zero, ones, rows):\n",
    "        eps = np.finfo(float).eps\n",
    "        z = zero / (rows + eps)\n",
    "        o = ones / (rows + eps)\n",
    "        return -(o * np.log2(o + eps) + z * np.log2(z + eps))\n",
    "\n",
    "dt = DT()\n",
    "root = dt.ID3(np.hstack([df_x_b_train, df_y_train]), np.arange(0, 57), stats.mode(df_y_train).mode[0])\n",
    "dt.predict(root, df_x_b_test, df_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
